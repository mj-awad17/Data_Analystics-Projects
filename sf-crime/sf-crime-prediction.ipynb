{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95778cdc",
   "metadata": {},
   "source": [
    "# **San Francisco Crime Project**\n",
    "\n",
    "- **Author:** Muhammad Jawad [@mjawad17]()\n",
    "- **Description:** Data analysis, exploration, visualization, and data mining on crime in SF\n",
    "- **Original dataset:** [SF Gov Crime dataset](https://data.sfgov.org/Public-Safety/Police-Department-Incident-Reports-Historical-2003/tmnf-yvry/about_data)\n",
    "- **Kaggle dataset:** [Kaggle SF Crime](https://www.kaggle.com/competitions/sf-crime/overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15892a05",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid #4CAF50; border-radius: 10px; padding: 20px; background-color: #f9f9f9; font-family: Arial, sans-serif; color: #333;\">\n",
    "    <h2 style=\"color: #4CAF50;\">Author Overview</h2>\n",
    "    <!-- Round image centered -->\n",
    "    <img src=\"https://avatars.githubusercontent.com/u/77524488?s=400&u=5ee60100c5daf1eb876be2bc80aaa0e9e85969c3&v=4\" alt=\"Author Image\" style=\"border-radius: 12%; width: 200px; height: 200px; margin-bottom: 20px; border: 2px solid green; display: block; margin-left: auto; margin-right: auto;\">\n",
    "    <p>I am <strong>Muhammad Jawad</strong>, a passionate data analyst dedicated to leveraging data to drive meaningful insights and support decision-making. With a strong foundation in computer science, I continuously seek to enhance my skills in analytical thinking and data-driven solutions. ðŸ“Š</p>\n",
    "    <h3 style=\"color: #4CAF50;\">What Do I Know?</h3>\n",
    "    <p>I excel at extracting valuable insights from data using Python, SQL, and data visualization tools like Power BI and Tableau. My experience includes analyzing insurance and medical data, as well as performing exploratory data analysis to uncover trends and patterns. I'm committed to improving my statistical analysis and reporting abilities to solve complex problems effectively. ðŸ“š</p>\n",
    "    <h3 style=\"color: #4CAF50;\">What Am I Doing Right Now?</h3>\n",
    "    <p>Currently, I am focused on expanding my knowledge in data science, particularly in machine learning and advanced analytics. I am eager to apply my theoretical knowledge to real-world projects that challenge me and contribute to organizational success. ðŸŽ¯</p>\n",
    "    <h3 style=\"color: #4CAF50;\">My Goal:</h3>\n",
    "    <p>To utilize my data analysis and data science skills to create value for companies by supporting their growth objectives. I am enthusiastic about learning new concepts and sharing my experiences with others. If youâ€™re interested in discussing projects, collaborating, or exchanging ideas, I would love to connect!</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31415403",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "- Introduction\n",
    "    - SF Crime Dataset\n",
    "- Basic Preparation\n",
    "    - Import libraries\n",
    "    - Load data\n",
    "- Data Exploration/Analysis Extension\n",
    "- Data Preprocessing\n",
    "    - Data Imputation/Removal\n",
    "    - Feature Engineering\n",
    "    - Feature Encoding\n",
    "- Build Machine Learning Models\n",
    "    - Train different baseline models\n",
    "    - Analyze results\n",
    "- Model Selection\n",
    "- Hyperparameter tuning\n",
    "- Train Model with optimal hyperparameters\n",
    "- Feature Selection\n",
    "    - Feature Importance\n",
    "    - Feature Removal\n",
    "- Train Final Model\n",
    "- Model Evaluation\n",
    "- Summary\n",
    "<!-- - Kaggle Submission -->\n",
    "- Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813f0a25",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938f2ccf",
   "metadata": {},
   "source": [
    "## SF Crime Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa74ed1c",
   "metadata": {},
   "source": [
    "This dataset includes information about crime incidents reported by the **San Francisco Police Department (SFPD)**. It covers data from _January 1, 2003, to May 13, 2015_.\n",
    "\n",
    "The dataset is divided into **two groups**: a training set and a test set. These sets rotate weekly. This means that in odd weeks (like the 1st, 3rd, 5th, and 7th weeks), the data is used for the test set. In even weeks (like the 2nd, 4th, 6th, and 8th weeks), the data is used for the training set.\n",
    "\n",
    "The main **objective** of this dataset is to predict the category of crime that took place in San Francisco based on the available information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c5938d",
   "metadata": {},
   "source": [
    "### Data Fields\n",
    "- **Dates** - timestamp of the crime incident\n",
    "- **Category** - category of the crime incident (only in train.csv). This is the target variable you are going to predict.\n",
    "- **Descript** - detailed description of the crime incident (only in train.csv)\n",
    "- **DayOfWeek** - the day of the week\n",
    "- **PdDistrict** - name of the Police Department District\n",
    "- **Resolution** - how the crime incident was resolved (only in train.csv)\n",
    "- **Address** - the approximate street address of the crime incident\n",
    "- **X** - Longitude\n",
    "- **Y** - Latitude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebba474",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "In this Jupyter notebook, I will take you through the entire process of creating a machine learning model using the open-source San Francisco Crime dataset. This will be a step-by-step journey that includes several important stages.\n",
    "\n",
    "First, I will explore and analyze the data to understand its structure and contents. This is a crucial step that helps identify patterns and insights within the data. Next, I will preprocess the data, which is a significant part of this project. This step involves cleaning the data and performing feature engineering to create useful variables for the model.\n",
    "\n",
    "After preparing the data, I will try out different machine learning algorithms to see which one works best for this dataset. I will determine the most effective model and then fine-tune its hyperparameters to improve its performance. Finally, I will evaluate the chosen model using a metric called multiclass log loss to assess how well it predicts the categories of crime.\n",
    "\n",
    "Since this project is based on an older Kaggle competition, I will avoid looking for external resources or past Kaggle notebooks. My goal is to enhance my coding skills for an end-to-end data science project and to become more familiar with Python data science libraries. I also hope to uncover interesting insights and discover cool patterns while working with this dataset. So, letâ€™s get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfd8f5f",
   "metadata": {},
   "source": [
    "# Basic Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46cb253",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ac522d",
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Muhammad Jawad (https://github.com/mj-awad17)\"\n",
    "\n",
    "# linear algebra\n",
    "import numpy as np\n",
    "\n",
    "# data manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import style\n",
    "%matplotlib inline\n",
    "style.use('ggplot')\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "\n",
    "# machince learning algorithms\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, Perceptron\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# model evaluation metrics\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# model selection and tuning\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, StratifiedGroupKFold\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "# clustering\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# mathematical fundtions\n",
    "import math\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328ba0f1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
